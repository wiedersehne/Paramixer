config = {
    "adding":{
        "models":{
            "Paramixer":{
                "name": "paramixer",
                "add_init_linear_layer": True,
                "vocab_size": 1,
                "embedding_size": 32,
                "dim": 32,
                "pooling_type": "FLATTEN",
                "head": ['linear'],
                "n_class": 1,
                "n_channels_V": 32,
                "use_cuda": True,
                "use_residuals": True,
                "use_pos_embedding": False,
                "problem": "adding",
                "protocol": "chord",
                'n_layers': 1
            },
            "Transformer":{
                "name": "transformer",
                "vocab_size": 1,
                "add_init_linear_layer": True,
                "dim": 32,
                "depth": 1,
                "heads": 1,
                "pooling_type": "FLATTEN",
                "head": ['linear'],
                "n_class": 1,
                "use_cuda": True,
                "use_pos_embedding": False,
                "problem": "adding"
            },
            "Linformer":{
                "name": "linformer",
                "vocab_size": 1,
                "add_init_linear_layer": True,
                "dim": 32,
                "depth": 1,
                "heads": 1,
                "pooling_type": "FLATTEN",
                "head": ['linear'],
                "n_class": 1,
                "use_cuda": True,
                "use_pos_embedding": False,
                "problem": "adding"
            },
            "Performer":{
                "name": "performer",
                "vocab_size": 1,
                "add_init_linear_layer": True,
                "dim": 32,
                "depth": 1,
                "heads": 1,
                "pooling_type": "FLATTEN",
                "head": ['linear'],
                "n_class": 1,
                "use_cuda": True,
                "use_pos_embedding": False,
                "problem": "adding"
            },
            "Reformer":{
                "name": "reformer",
                "vocab_size": 1,
                "add_init_linear_layer": True,
                "dim": 32,
                "depth": 1,
                "heads": 1,
                "pooling_type": "FLATTEN",
                "head": ['linear'],
                "n_class": 1,
                "use_cuda": True,
                "use_pos_embedding": False,
                "problem": "adding"
            },
            "Nystromformer":{
                "name": "nystromformer",
                "vocab_size": 1,
                "add_init_linear_layer": True,
                "dim": 32,
                "depth": 1,
                "heads": 1,
                "pooling_type": "FLATTEN",
                "head": ['linear'],
                "n_class": 1,
                "use_cuda": True,
                "use_pos_embedding": False,
                "problem": "adding"
            },
            "LStransformer":{
                "name": "lstransformer",
                "vocab_size": 1,
                "add_init_linear_layer": True,
                "dim": 32,
                "depth": 1,
                "heads": 1,
                "pooling_type": "FLATTEN",
                "head": ['linear'],
                "n_class": 1,
                "use_cuda": True,
                "use_pos_embedding": False,
                "problem": "adding"
            },
        },
        "training":{
            "device_id": 0,
            "batch_size":40,
            "learning_rate":0.001,
            "eval_frequency":1,
            "num_train_steps":50 # Fixed for all models
        }
    },
    "order":{
        "models":{
            "Paramixer":{
                "name": "paramixer",
                "add_init_linear_layer": False,
                "vocab_size": 6,
                "embedding_size": 32,
                "dim": 32,
                "pooling_type": "FLATTEN",
                "head": ['linear'],
                "n_class": 4,
                "n_channels_V": 8,
                "use_cuda": True,
                "use_residuals": True,
                "use_pos_embedding": True,
                "problem": "chord",
                'n_layers': 1
            },
            "Transformer":{
                "name": "transformer",
                "vocab_size": 6,
                "add_init_linear_layer": False,
                "dim": 32,
                "depth": 1,
                "heads": 1,
                "pooling_type": "FLATTEN",
                "head": ['linear'],
                "n_class": 4,
                "use_cuda": True,
                "use_pos_embedding": True,
                "problem": "order"
            },
            "Linformer":{
                "name": "linformer",
                "vocab_size": 6,
                "add_init_linear_layer": False,
                "dim": 32,
                "depth": 1,
                "heads": 1,
                "pooling_type": "FLATTEN",
                "head": ['linear'],
                "n_class": 4,
                "use_cuda": True,
                "use_pos_embedding": True,
                "problem": "order"
            },
            "Performer":{
                "name": "performer",
                "vocab_size": 6,
                "add_init_linear_layer": False,
                "dim": 32,
                "depth": 1,
                "heads": 1,
                "pooling_type": "FLATTEN",
                "head": ['linear'],
                "n_class": 4,
                "use_cuda": True,
                "use_pos_embedding": True,
                "problem": "order"
            },
            "Reformer":{
                "name": "reformer",
                "vocab_size": 6,
                "add_init_linear_layer": True,
                "dim": 32,
                "depth": 1,
                "heads": 1,
                "pooling_type": "FLATTEN",
                "head": ['linear'],
                "n_class": 4,
                "use_cuda": True,
                "use_pos_embedding": True,
                "problem": "adding"
            },
            "Nystromformer":{
                "name": "nystromformer",
                "vocab_size": 6,
                "add_init_linear_layer": True,
                "dim": 32,
                "depth": 1,
                "heads": 1,
                "pooling_type": "FLATTEN",
                "head": ['linear'],
                "n_class": 4,
                "use_cuda": True,
                "use_pos_embedding": True,
                "problem": "adding"
            },
            "LStransformer":{
                "name": "lstransformer",
                "vocab_size": 1,
                "add_init_linear_layer": True,
                "dim": 32,
                "depth": 1,
                "heads": 1,
                "pooling_type": "FLATTEN",
                "head": ['linear'],
                "n_class": 4,
                "use_cuda": True,
                "use_pos_embedding": True,
                "problem": "adding"
            },
        },
        "training":{
            "device_id": 0,
            "batch_size": 40,
            "learning_rate": 0.001,
            "eval_frequency": 1,
            "num_train_steps": 30 # Fixed for all models
        }
    }
}
